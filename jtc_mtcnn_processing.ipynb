{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Folder Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from facenet_pytorch import MTCNN\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  3.72it/s]\n"
     ]
    }
   ],
   "source": [
    "# Takes 25 minutes\n",
    "# Sort train_small data into subfolders according to class\n",
    "data_dir = r\"C:\\Users\\jjuus\\OneDrive - purdue.edu\\ECE 50024\\Kaggle\"\n",
    "data_mat = pd.read_csv(join(data_dir, \"train_small.csv\"))\n",
    "\n",
    "indices = data_mat['Unnamed: 0']\n",
    "filenames = data_mat['File Name']\n",
    "classes = data_mat['Category']\n",
    "\n",
    "# print(data_mat)\n",
    "# print(indices[0])\n",
    "# print(filenames[0])\n",
    "# print(classes[0])\n",
    "# print()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))\n",
    "\n",
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Get starting/ending picture directories\n",
    "train_data_dir = join(data_dir, r\"train_small\\train_small\")\n",
    "jtc_data_dir = join(data_dir, r\"train_small_jtc\")\n",
    "jtc_crop_data_dir = join(data_dir, r\"train_small_jtc_cropped\")\n",
    "\n",
    "# Loop through all starting pictures\n",
    "# len(data_mat)\n",
    "for lcv in tqdm(range(10)):\n",
    "    # Get source filepath\n",
    "    src = join(train_data_dir, filenames[lcv])\n",
    "\n",
    "    # Get destination filepath\n",
    "    subfolder_name = classes[lcv].lower().replace(\" \", \"_\")\n",
    "    dst = join(jtc_data_dir, subfolder_name, filenames[lcv])\n",
    "\n",
    "    # # Move file (make dir if necessary)\n",
    "    # os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "    # shutil.copy2(src, dst)\n",
    "\n",
    "    # Try to crop file\n",
    "    curr_img = Image.open(src)\n",
    "    crop_dst = join(jtc_crop_data_dir, subfolder_name, filenames[lcv])\n",
    "    try:\n",
    "        curr_img_cropped = mtcnn(curr_img, save_path=crop_dst)\n",
    "    except:\n",
    "        try:\n",
    "            curr_img_cropped = mtcnn(curr_img.convert('RGB'), save_path=crop_dst)\n",
    "        except:\n",
    "            print(\"Still Failed \", filenames[lcv])\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mtcnn.select_largest:  True\n",
      "mtcnn.selection_method:  largest\n"
     ]
    }
   ],
   "source": [
    "print(\"mtcnn.select_largest: \", mtcnn.select_largest)\n",
    "print(\"mtcnn.selection_method: \", mtcnn.selection_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 837/69540 [02:48<3:17:22,  5.80it/s] c:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\PIL\\Image.py:981: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      " 86%|████████▌ | 59737/69540 [3:30:04<26:41,  6.12it/s]   c:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:870: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n",
      "100%|██████████| 69540/69540 [4:05:43<00:00,  4.72it/s]   \n"
     ]
    }
   ],
   "source": [
    "# Takes 3.8 hours\n",
    "# Sort train_small data into subfolders according to class\n",
    "data_dir = r\"C:\\Users\\jjuus\\OneDrive - purdue.edu\\ECE 50024\\Kaggle\"\n",
    "data_mat = pd.read_csv(join(data_dir, \"train.csv\"))\n",
    "\n",
    "indices = data_mat['Unnamed: 0']\n",
    "filenames = data_mat['File Name']\n",
    "classes = data_mat['Category']\n",
    "\n",
    "# print(data_mat)\n",
    "# print(indices[0])\n",
    "# print(filenames[0])\n",
    "# print(classes[0])\n",
    "# print()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))\n",
    "\n",
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Get starting/ending picture directories\n",
    "train_data_dir = join(data_dir, r\"train\\train\")\n",
    "jtc_data_dir = join(data_dir, r\"train_jtc\")\n",
    "jtc_crop_data_dir = join(data_dir, r\"train_jtc_cropped2\")\n",
    "\n",
    "# Loop through all starting pictures\n",
    "# len(data_mat)\n",
    "for lcv in tqdm(range(len(data_mat))):\n",
    "    # Get source filepath\n",
    "    src = join(train_data_dir, filenames[lcv])\n",
    "\n",
    "    # Get destination filepath\n",
    "    subfolder_name = classes[lcv].lower().replace(\" \", \"_\")\n",
    "    dst = join(jtc_data_dir, subfolder_name, filenames[lcv])\n",
    "\n",
    "    # # Move file (make dir if necessary)\n",
    "    # os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "    # shutil.copy2(src, dst)\n",
    "\n",
    "    # Try to crop file\n",
    "    curr_img = Image.open(src)\n",
    "    crop_dst = join(jtc_crop_data_dir, subfolder_name, filenames[lcv])\n",
    "    try:\n",
    "        curr_img_cropped = mtcnn(curr_img, save_path=crop_dst)\n",
    "    except:\n",
    "        try:\n",
    "            curr_img_cropped = mtcnn(curr_img.convert('RGB'), save_path=crop_dst)\n",
    "        except:\n",
    "            print(\"Still Failed \", filenames[lcv])\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.jpg\n",
      "1.jpg\n",
      "2.jpg\n",
      "3.jpg\n",
      "4.jpg\n",
      "5.jpg\n",
      "6.jpg\n",
      "7.jpg\n",
      "8.jpg\n",
      "9.jpg\n"
     ]
    }
   ],
   "source": [
    "for lcv in range(10):\n",
    "    print(str(lcv) + \".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4977/4977 [17:45<00:00,  4.67it/s]  \n"
     ]
    }
   ],
   "source": [
    "# Sort train_small data into subfolders according to class\n",
    "data_dir = r\"C:\\Users\\jjuus\\OneDrive - purdue.edu\\ECE 50024\\Kaggle\"\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))\n",
    "\n",
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Get starting/ending picture directories\n",
    "test_data_dir = join(data_dir, r\"test\\test\")\n",
    "jtc_data_dir = join(data_dir, r\"test_jtc\")\n",
    "jtc_crop_data_dir = join(data_dir, r\"test_jtc_cropped2\")\n",
    "\n",
    "# Loop through all starting pictures\n",
    "# 4977\n",
    "for lcv in tqdm(range(4977)):\n",
    "    # Get source filepath\n",
    "    curr_filename = str(lcv) + \".jpg\"\n",
    "    src = join(test_data_dir, curr_filename)\n",
    "\n",
    "    # Try to crop file\n",
    "    curr_img = Image.open(src)\n",
    "    crop_dst = join(jtc_crop_data_dir, curr_filename)\n",
    "    try:\n",
    "        curr_img_cropped = mtcnn(curr_img, save_path=crop_dst)\n",
    "    except:\n",
    "        try:\n",
    "            curr_img_cropped = mtcnn(curr_img.convert('RGB'), save_path=crop_dst)\n",
    "        except:\n",
    "            print(\"Still Failed \", filenames[lcv])\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing:  133\n",
      "Missing:  166\n",
      "Missing:  210\n",
      "Missing:  217\n",
      "Missing:  282\n",
      "Missing:  289\n",
      "Missing:  317\n",
      "Missing:  343\n",
      "Missing:  430\n",
      "Missing:  545\n",
      "Missing:  585\n",
      "Missing:  609\n",
      "Missing:  701\n",
      "Missing:  851\n",
      "Missing:  927\n",
      "Missing:  1004\n",
      "Missing:  1141\n",
      "Missing:  1154\n",
      "Missing:  1351\n",
      "Missing:  1362\n",
      "Missing:  1480\n",
      "Missing:  1499\n",
      "Missing:  1658\n",
      "Missing:  1734\n",
      "Missing:  1749\n",
      "Missing:  1826\n",
      "Missing:  1868\n",
      "Missing:  1922\n",
      "Missing:  1936\n",
      "Missing:  1984\n",
      "Missing:  1997\n",
      "Missing:  2008\n",
      "Missing:  2388\n",
      "Missing:  2411\n",
      "Missing:  2431\n",
      "Missing:  2523\n",
      "Missing:  2545\n",
      "Missing:  2547\n",
      "Missing:  2581\n",
      "Missing:  2583\n",
      "Missing:  2777\n",
      "Missing:  2780\n",
      "Missing:  2785\n",
      "Missing:  2923\n",
      "Missing:  3010\n",
      "Missing:  3088\n",
      "Missing:  3148\n",
      "Missing:  3209\n",
      "Missing:  3322\n",
      "Missing:  3469\n",
      "Missing:  3558\n",
      "Missing:  3568\n",
      "Missing:  3731\n",
      "Missing:  3744\n",
      "Missing:  3752\n",
      "Missing:  3819\n",
      "Missing:  3842\n",
      "Missing:  3905\n",
      "Missing:  3973\n",
      "Missing:  4237\n",
      "Missing:  4337\n",
      "Missing:  4350\n",
      "Missing:  4390\n",
      "Missing:  4610\n",
      "Missing:  4757\n",
      "Missing:  4780\n",
      "Missing:  4888\n",
      "Missing:  4923\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find missing test images\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os.path\n",
    "import csv\n",
    "from os.path import join\n",
    "import shutil\n",
    "\n",
    "# Get lookup class csv\n",
    "data_dir = r\"C:\\Users\\jjuus\\OneDrive - purdue.edu\\ECE 50024\\Kaggle\"\n",
    "my_classes_mat = pd.read_csv(join(data_dir, \"category_lookup.csv\"))\n",
    "my_classes_mat\n",
    "their_name_vec = my_classes_mat['their_name']\n",
    "\n",
    "test_img_path = r\"C:\\Users\\jjuus\\OneDrive - purdue.edu\\ECE 50024\\Kaggle\\test_jtc_cropped3\"\n",
    "original_test_path = r\"C:\\Users\\jjuus\\OneDrive - purdue.edu\\ECE 50024\\Kaggle\\test\\test\"\n",
    "dst_missing_path = r\"C:\\Users\\jjuus\\OneDrive - purdue.edu\\ECE 50024\\Kaggle\\test_jtc_missing3\"\n",
    "\n",
    "missing_list = []\n",
    "for lcv in range(4977):\n",
    "    # Get source filepath\n",
    "    curr_filename = str(lcv) + \".jpg\"\n",
    "    src = join(test_img_path, curr_filename)\n",
    "\n",
    "    # Test to see if input file exists\n",
    "    if not os.path.isfile(src):\n",
    "        print(\"Missing: \", lcv)\n",
    "        missing_list.append(lcv)\n",
    "\n",
    "        # Move file (make dir if necessary)\n",
    "        orig_src = join(original_test_path, curr_filename)\n",
    "        dst = join(dst_missing_path, curr_filename)\n",
    "        os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "        shutil.copy2(orig_src, dst)\n",
    "\n",
    "len(missing_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN, InceptionResnetV1, fixed_image_standardization, training\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort train_small data into subfolders according to class\n",
    "data_dir = r\"C:\\Users\\jjuus\\OneDrive - purdue.edu\\ECE 50024\\Kaggle\"\n",
    "\n",
    "# Get ending picture directories\n",
    "jtc_data_dir = join(data_dir, r\"train_small_jtc_test\")\n",
    "\n",
    "data_dir = jtc_data_dir\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 8\n",
    "workers = 0 if os.name == 'nt' else 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(\n",
    "    image_size=160, margin=0, min_face_size=20,\n",
    "    thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 of 3"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (32,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 15\u001b[0m\n\u001b[0;32m      7\u001b[0m loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[0;32m      8\u001b[0m     dataset,\n\u001b[0;32m      9\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39mworkers,\n\u001b[0;32m     10\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m     11\u001b[0m     collate_fn\u001b[38;5;241m=\u001b[39mtraining\u001b[38;5;241m.\u001b[39mcollate_pil\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m---> 15\u001b[0m     mtcnn(x, save_path\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124mBatch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(loader)), end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Remove mtcnn to reduce GPU memory usage\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\anaconda3\\envs\\ECE50024\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\OneDrive\\Documents\\git\\ECE50024_Kaggle\\facenet_pytorch\\models\\mtcnn.py:261\u001b[0m, in \u001b[0;36mMTCNN.forward\u001b[1;34m(self, img, save_path, return_prob)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;66;03m# Select faces\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_all:\n\u001b[1;32m--> 261\u001b[0m     batch_boxes, batch_probs, batch_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselect_boxes(\n\u001b[0;32m    262\u001b[0m         batch_boxes, batch_probs, batch_points, img, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselection_method\n\u001b[0;32m    263\u001b[0m     )\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# Extract faces\u001b[39;00m\n\u001b[0;32m    265\u001b[0m faces \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract(img, batch_boxes, save_path)\n",
      "File \u001b[1;32mc:\\Users\\jjuus\\OneDrive\\Documents\\git\\ECE50024_Kaggle\\facenet_pytorch\\models\\mtcnn.py:444\u001b[0m, in \u001b[0;36mMTCNN.select_boxes\u001b[1;34m(self, all_boxes, all_probs, all_points, imgs, method, threshold, center_weight)\u001b[0m\n\u001b[0;32m    441\u001b[0m     selected_points\u001b[38;5;241m.\u001b[39mappend(point)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_mode:\n\u001b[1;32m--> 444\u001b[0m     selected_boxes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(selected_boxes)\n\u001b[0;32m    445\u001b[0m     selected_probs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(selected_probs)\n\u001b[0;32m    446\u001b[0m     selected_points \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(selected_points)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (32,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "dataset = datasets.ImageFolder(data_dir, transform=transforms.Resize((512, 512)))\n",
    "dataset.samples = [\n",
    "    (p, p.replace(data_dir, data_dir + '_cropped'))\n",
    "        for p, _ in dataset.samples\n",
    "]\n",
    "        \n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    num_workers=workers,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=training.collate_pil\n",
    ")\n",
    "\n",
    "for i, (x, y) in enumerate(loader):\n",
    "    mtcnn(x, save_path=y)\n",
    "    print('\\rBatch {} of {}'.format(i + 1, len(loader)), end='')\n",
    "    \n",
    "# Remove mtcnn to reduce GPU memory usage\n",
    "del mtcnn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECE50024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
